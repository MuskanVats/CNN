{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xME-qa_Y5rRA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "jhRumjfBfeXI",
    "outputId": "7eacc308-844f-4655-be25-1b50413ddc4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrGDsDg4m2BU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kP6ZC3S6mt9G"
   },
   "source": [
    "Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDEtG0rxmxto"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEr-XqrLBSpt"
   },
   "source": [
    "Building CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3vz3A2NDssI"
   },
   "source": [
    "Step 1: Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFa2XB4X-aVA"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qSWfTQM-erE"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVdancpMD-__"
   },
   "source": [
    "Step 2: Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3pGUQnd-iv-"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cV0ubab_D58p"
   },
   "source": [
    "Building second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7xeF4mr-j8s"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAkC78mHEQm1"
   },
   "source": [
    "Step 3: Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXXs3sVd-1hI"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PpEdwVwdEsDX"
   },
   "source": [
    "Step 4: Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UH4FK66R_MZA"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jrmZDHujExH6"
   },
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0uJFq3M_PZD"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDpZO4MrE78R"
   },
   "source": [
    "Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5FUQRj6_Pvk"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLCiUuKqFApm"
   },
   "source": [
    "Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txeaei7H_QFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 63 steps\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 255s 1s/step - loss: 0.6475 - accuracy: 0.6165 - val_loss: 0.6306 - val_accuracy: 0.6370\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 0.5798 - accuracy: 0.6949 - val_loss: 0.5318 - val_accuracy: 0.7385\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 116s 463ms/step - loss: 0.5413 - accuracy: 0.7237 - val_loss: 0.5124 - val_accuracy: 0.7430\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 0.5157 - accuracy: 0.7404 - val_loss: 0.5206 - val_accuracy: 0.7485\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 0.4959 - accuracy: 0.7580 - val_loss: 0.5102 - val_accuracy: 0.7510\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 0.4770 - accuracy: 0.7690 - val_loss: 0.5311 - val_accuracy: 0.7425\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 0.4556 - accuracy: 0.7821 - val_loss: 0.4783 - val_accuracy: 0.7765\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 0.4435 - accuracy: 0.7914 - val_loss: 0.4618 - val_accuracy: 0.7875\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 130s 520ms/step - loss: 0.4319 - accuracy: 0.7979 - val_loss: 0.4951 - val_accuracy: 0.7705\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 113s 452ms/step - loss: 0.4213 - accuracy: 0.8051 - val_loss: 0.4628 - val_accuracy: 0.7905\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 113s 452ms/step - loss: 0.3991 - accuracy: 0.8166 - val_loss: 0.4404 - val_accuracy: 0.8015\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 111s 444ms/step - loss: 0.3937 - accuracy: 0.8165 - val_loss: 0.4425 - val_accuracy: 0.8010\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 110s 442ms/step - loss: 0.3762 - accuracy: 0.8306 - val_loss: 0.4417 - val_accuracy: 0.8005\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 114s 456ms/step - loss: 0.3597 - accuracy: 0.8405 - val_loss: 0.4405 - val_accuracy: 0.8090\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 113s 450ms/step - loss: 0.3474 - accuracy: 0.8484 - val_loss: 0.4309 - val_accuracy: 0.8020\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 128s 512ms/step - loss: 0.3321 - accuracy: 0.8526 - val_loss: 0.4739 - val_accuracy: 0.8005\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 112s 448ms/step - loss: 0.3328 - accuracy: 0.8549 - val_loss: 0.4776 - val_accuracy: 0.7995\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 123s 493ms/step - loss: 0.3118 - accuracy: 0.8622 - val_loss: 0.4696 - val_accuracy: 0.7950\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 110s 442ms/step - loss: 0.2963 - accuracy: 0.8712 - val_loss: 0.4802 - val_accuracy: 0.8020\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 0.2876 - accuracy: 0.8776 - val_loss: 0.4406 - val_accuracy: 0.8025\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 111s 442ms/step - loss: 0.2694 - accuracy: 0.8866 - val_loss: 0.4663 - val_accuracy: 0.7980\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 0.2635 - accuracy: 0.8910 - val_loss: 0.4518 - val_accuracy: 0.8020\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 0.2600 - accuracy: 0.8889 - val_loss: 0.5044 - val_accuracy: 0.8025\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 0.2387 - accuracy: 0.9007 - val_loss: 0.5320 - val_accuracy: 0.7945\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 0.2265 - accuracy: 0.9056 - val_loss: 0.4904 - val_accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263f7089588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gzUCdJ_FIoN"
   },
   "source": [
    "Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mA6BgI8D_seO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKt1bhpB_s1H",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pilot = image.load_img(\"dataset/single_prediction/cat_or_dog_1.jpg\", target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pilot.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
